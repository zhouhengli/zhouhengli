<h1 id="About me" style="border-bottom: 2px solid #d3d3d3;">👀 About me: <a href="https://zhouhengli.github.io">https://zhouhengli.github.io/</a></h1>


<p style="line-height: 1.5; text-align: justify; font-size: 16px;"> 
    <span style="display: inline-block; text-indent: 2em;">I am currently a 4th year Ph.D. student in the College of Control Science and Engineering at <img src="./ico/zju.jpg" style="width: 16px; height: auto;" /> <sa href="https://www.zju.edu.cn/english/ "  target=_blank >Zhejiang University</sa>
, Hangzhou, China, under the supervision of  <sa href="https://scholar.google.com.hk/citations?hl=zh-CN&user=7ZZ_-m0AAAAJ" target=_blank  >Prof. Lei Xie</sa> and <sa href="https://scholar.google.com.hk/citations?hl=zh-CN&user=9rfFRjgAAAAJ" target=_blank  >Prof. Hongye Su</sa>.  Previously, I was mentored by <sa href="https://yilundu.github.io/" target=_blank  >Prof. Yilun Du</sa> from  Harvard University. ✨ Enjoyments of life: 🎲 Board Games (Splendor, Seven Wonders: Duel, etc), 👣 hiking, 🎾 tennis, 🏓 ping-pong, 🗺️ traveling. </span>

    
</p>   

<div style="display: flex; justify-content: space-between; align-items: center; border-bottom: 2px solid #d3d3d3;">
  <h1 id="Research-section">🎯 Research</h1>
</div>

<p style="line-height: 1.5; text-align: justify; font-size: 16px;"> 
        <span style="display: inline-block; text-indent: 2em;">My ultimate goal is to develop embodied intelligent autonomous systems capable of seamlessly interacting with the physical world. To achieve this, my research focuses on motion planning techniques driven by physics-informed generative models, enabling safe generalization to out-of-distribution (OOD) scenarios. Currently, I am exploring planning strategies for both autonomous vehicle racing and drone racing, as well as advancing world models, with particular emphasis on the following key areas:</span> <br>
    <span style="display: inline-block;">⭐ <strong>End-to-End Motion Planning for Unmanned Systems</strong>: End-to-end approaches can directly learn motion patterns from data distributions, effectively bypassing the need for complex planning and control (PnC) rules. Conditional diffusion models, informed by physical and task-specific information, enable stable and safe generalization in motion generation, thus providing strong guarantees for overall system performance.</span> <br>  
    <span style="display: inline-block;">⭐ <strong>Multimodal Generative Models</strong>: Multimodal inputs form the foundation of intelligent systems. By leveraging classifier-free guidance (CFG) for model composition, diverse modalities—such as images, language, and states—can be efficiently integrated, enabling the embodied intelligent motion generation.</span> <br>     
    <span style="display: inline-block;">⭐ <strong>Physics-Informed World Models</strong>: At present, world models still face challenges in maintaining temporal consistency during long-horizon sequence generation. By incorporating physical knowledge, world models can generate in latent spaces that adhere to physical laws, thereby ensuring stability and consistency in their predictions.</span>  
    <br>   
    <span style="display: inline-block; text-indent: 2em;">I am also actively involved in applying these techniques to <sa href="https://f1tenth.org/"  target=_blank >Roboracer competition</sa>. If any of these topics caught your interest, feel free to drop me emails (📨 zh_li@zju.edu.cn). I enjoy collaborating on interesting projects and <strong>making amazing things happen together</strong>!</span>

<div style="display: flex; justify-content: space-between; align-items: center; border-bottom: 2px solid #d3d3d3;">
  <h1 id="Project-section">👨‍💻 Project statistics</h1>
</div>


[![Zhouheng's GitHub stats](https://github-readme-stats-three-psi-22.vercel.app/api?username=zhouhengli)](https://github.com/zhouhengli/github-readme-stats)

